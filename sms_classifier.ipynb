{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCC dataset preloaded as 'sms_data'; else load manually\n",
    "# sms_data = pd.read_csv('SMSSpamCollection', sep='\t', names=['label','message'])\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(sms_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_data['label'])\n",
    "test_labels = le.transform(test_data['label'])\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_data['message'])\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['message'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['message'])\n",
    "\n",
    "max_len = 50\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=16, input_length=max_len),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_message(message):\n",
    "    seq = tokenizer.texts_to_sequences([message])\n",
    "    padded = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')\n",
    "    prob = float(model.predict(padded)[0][0])\n",
    "    label = 'spam' if prob >= 0.5 else 'ham'\n",
    "    return [prob, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_message('Congratulations! You won a free ticket!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}